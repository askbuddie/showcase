{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "three-dictionary"
      },
      "source": [
        "### Transfer learning and fine tuning"
      ],
      "id": "three-dictionary"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agreed-poison"
      },
      "source": [
        "#### To classify between Cat and Dogs using pre-trained model \n"
      ],
      "id": "agreed-poison"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spread-stamp"
      },
      "source": [
        "<html>\n",
        "<body>\n",
        "    <h3> Two ways for pretrained model</h3>\n",
        "<ul>\n",
        "<li> Feature extraction</li>\n",
        "<li> Fine Tuning </li>\n",
        "</ul>\n",
        "</body>\n",
        "<html>"
      ],
      "id": "spread-stamp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "authentic-shade"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "id": "authentic-shade",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floppy-policy"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "id": "floppy-policy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parental-width"
      },
      "source": [
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                 shuffle = True,\n",
        "                                                 batch_size= BATCH_SIZE,\n",
        "                                                  image_size = IMG_SIZE)"
      ],
      "id": "parental-width",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruled-christian"
      },
      "source": [
        "class_names = train_dataset.class_names\n",
        "plt.figure(figsize =(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3,i+1)\n",
        "        plt.imshow(images[i].numpy().astype('uint8'))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "id": "ruled-christian",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "injured-idaho"
      },
      "source": [
        "#how many batches of data available in validation set\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)#returns the cardinality\n",
        "test_dataset = validation_dataset.take(val_batches//5) #20%\n",
        "validation_dataset = validation_dataset.skip(val_batches //5)"
      ],
      "id": "injured-idaho",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "introductory-railway"
      },
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ],
      "id": "introductory-railway",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "supported-issue"
      },
      "source": [
        "#### Use data augmentation"
      ],
      "id": "supported-issue"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "angry-school"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    \n",
        "])"
      ],
      "id": "angry-school",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inner-opportunity"
      },
      "source": [
        "for image,_ in train_dataset.take(1):\n",
        "    plt.figure(figsize = (10,10))\n",
        "    first_image = image[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3,i+1)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image,0))\n",
        "        plt.imshow(augmented_image[0]/255)\n",
        "        plt.axis('off')\n",
        "        \n",
        "   "
      ],
      "id": "inner-opportunity",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enormous-pound"
      },
      "source": [
        "### Rescale Pixel values"
      ],
      "id": "enormous-pound"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prescribed-snake"
      },
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale  = tf.keras.layers.experimental.preprocessing.Rescaling(1./127)"
      ],
      "id": "prescribed-snake",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automated-clause"
      },
      "source": [
        "#### Create the base model from the pre-trained convnets"
      ],
      "id": "automated-clause",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furnished-cassette"
      },
      "source": [
        "#### base model from pre-trained model MobileNet V2"
      ],
      "id": "furnished-cassette"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "under-dance"
      },
      "source": [
        "#### Feature Extraction"
      ],
      "id": "under-dance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noted-symphony"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE+(3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape = IMG_SHAPE,\n",
        "                                              include_top = False,# discards the classification layers at the top\n",
        "                                              weights = 'imagenet')"
      ],
      "id": "noted-symphony",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quantitative-parker"
      },
      "source": [
        "image_batch,label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "id": "quantitative-parker",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stable-brunswick"
      },
      "source": [
        "#### Feature Extraction"
      ],
      "id": "stable-brunswick"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "labeled-shakespeare"
      },
      "source": [
        "### freeze the convolution base \n",
        "#### It will freeze the weights of the layers to prevent them from being updated while trainig"
      ],
      "id": "labeled-shakespeare"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "presidential-darwin"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "id": "presidential-darwin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sunset-verification"
      },
      "source": [
        "#### layers.trainable is kept false because, at the time of batchNormalization,it may update variances and mean. So,this updates may distroy the things that our model has learned"
      ],
      "id": "sunset-verification"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "devoted-mapping"
      },
      "source": [
        " base_model.summary()"
      ],
      "id": "devoted-mapping",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assumed-edwards"
      },
      "source": [
        "##### Add a clasification head "
      ],
      "id": "assumed-edwards"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedicated-assault"
      },
      "source": [
        "###### Average over the spatial 5x5 spatial locations\n"
      ],
      "id": "dedicated-assault"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "entertaining-pasta"
      },
      "source": [
        "#### it converts (32 , 5,5,1280) into 32,1280\n",
        "#### using GlobalAveragePooling2D\n",
        "To generate predictions from the block of features, average over the spatial 5x5 spatial locations, using a tf.keras.layers.GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image."
      ],
      "id": "entertaining-pasta"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "finished-bracelet"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "id": "finished-bracelet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assured-program"
      },
      "source": [
        "### convert these feature into single prediction per image\n"
      ],
      "id": "assured-program"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "referenced-throw"
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "id": "referenced-throw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tough-manhattan"
      },
      "source": [
        "#### build the model chaining together the data augmentation"
      ],
      "id": "tough-manhattan"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "casual-agent"
      },
      "source": [
        "inputs  = tf.keras.Input(shape = (160,160,3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x,training = False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs,outputs)"
      ],
      "id": "casual-agent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accessory-margin"
      },
      "source": [
        "#### Compile the model"
      ],
      "id": "accessory-margin"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "respected-perspective"
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr = base_learning_rate),\n",
        "             loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "             metrics = ['accuracy'])"
      ],
      "id": "respected-perspective",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stainless-knock"
      },
      "source": [
        ""
      ],
      "id": "stainless-knock",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wound-classic"
      },
      "source": [
        "model.summary()"
      ],
      "id": "wound-classic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attempted-boulder"
      },
      "source": [
        "len(model.trainable_variables)"
      ],
      "id": "attempted-boulder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reverse-treatment"
      },
      "source": [
        "##### out of 2.5M parameters , only 1.2K are used trainable where other are\n",
        "frozen"
      ],
      "id": "reverse-treatment"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "annual-least"
      },
      "source": [
        "##### Train the model"
      ],
      "id": "annual-least"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "equal-nickname"
      },
      "source": [
        "initial_epochs = 10\n",
        "loss0,accuracy0 = model.evaluate(validation_dataset)"
      ],
      "id": "equal-nickname",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irish-maintenance"
      },
      "source": [
        "print(\"Initial Loss: {:.2f}\".format(loss0))\n",
        "print(\"Initial Accuracy: {:.2f}\".format(accuracy0))"
      ],
      "id": "irish-maintenance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "considerable-programming",
        "outputId": "34bbdb0c-d725-4f0b-b291-eb3bfb3f2a04"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                   epochs = initial_epochs,\n",
        "                   validation_data = validation_dataset)"
      ],
      "id": "considerable-programming",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 49s 727ms/step - loss: 0.3246 - accuracy: 0.8410 - val_loss: 0.1133 - val_accuracy: 0.9579\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 45s 717ms/step - loss: 0.1690 - accuracy: 0.9295 - val_loss: 0.0797 - val_accuracy: 0.9740\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 45s 713ms/step - loss: 0.1480 - accuracy: 0.9365 - val_loss: 0.0692 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 45s 720ms/step - loss: 0.1247 - accuracy: 0.9485 - val_loss: 0.0579 - val_accuracy: 0.9752\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 45s 706ms/step - loss: 0.1269 - accuracy: 0.9525 - val_loss: 0.0602 - val_accuracy: 0.9802\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 45s 715ms/step - loss: 0.1268 - accuracy: 0.9440 - val_loss: 0.0534 - val_accuracy: 0.9777\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 45s 716ms/step - loss: 0.1172 - accuracy: 0.9520 - val_loss: 0.0514 - val_accuracy: 0.9790\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 45s 716ms/step - loss: 0.1215 - accuracy: 0.9495 - val_loss: 0.0518 - val_accuracy: 0.9765\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9510"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liable-portfolio"
      },
      "source": [
        "## Learning curves\n"
      ],
      "id": "liable-portfolio",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "requested-radical"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "id": "requested-radical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moved-present"
      },
      "source": [
        "#### Fine tuning"
      ],
      "id": "moved-present"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suited-research"
      },
      "source": [
        "#### fine tune is to train the weights on the top of the layers of the pre trained model"
      ],
      "id": "suited-research"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opposed-provision"
      },
      "source": [
        "### train the weights on the top of pretrained model along with the classifier you added"
      ],
      "id": "opposed-provision"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "photographic-humanity"
      },
      "source": [
        "##### unfreeze the top layer"
      ],
      "id": "photographic-humanity"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "structured-former"
      },
      "source": [
        "base_model.trainable = True"
      ],
      "id": "structured-former",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comic-sport"
      },
      "source": [
        "# let's take a look to see how many layers are in base model\n",
        "print(\"Number of layers in base model: \",len(base_model.layers))\n",
        "## fine tune from this layers onwards\n",
        "fine_tune_at = 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False"
      ],
      "id": "comic-sport",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "professional-railway"
      },
      "source": [
        "### Compile the model\n"
      ],
      "id": "professional-railway"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quality-transition"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "             optimizer = tf.keras.optimizers.RMSprop(lr = base_learning_rate/10),\n",
        "             metrics = ['accuracy'])\n"
      ],
      "id": "quality-transition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "matched-teacher"
      },
      "source": [
        "model.summary()"
      ],
      "id": "matched-teacher",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assigned-drama"
      },
      "source": [
        "len(model.trainable_variables)"
      ],
      "id": "assigned-drama",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "configured-curve"
      },
      "source": [
        "### continue the training"
      ],
      "id": "configured-curve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "employed-cameroon"
      },
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs+fine_tune_epochs\n",
        "history_fine = model.fit(train_dataset,\n",
        "                        epochs = total_epochs,\n",
        "                        initial_epoch = history.epoch[-1],\n",
        "                        validation_data = validation_dataset)"
      ],
      "id": "employed-cameroon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "american-japanese"
      },
      "source": [
        "acc+=history_fine.history['accuracy']\n",
        "val_acc = history_fine.history['val_accuracy']\n",
        "loss+=history_fine.history['loss']\n",
        "val_loss+=history_fine.history['val_loss']"
      ],
      "id": "american-japanese",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "binding-fight"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "id": "binding-fight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weekly-centre"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ],
      "id": "weekly-centre",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "educational-analysis"
      },
      "source": [
        "### Now test the data"
      ],
      "id": "educational-analysis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vital-surfing"
      },
      "source": [
        "#Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "predictions = tf.nn.sigmoid(predictions)\n",
        "\n",
        "predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "print('Predictions:\\n', predictions.numpy())\n",
        "print('Labels:\\n', label_batch)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    \n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "    plt.title(class_names[predictions[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "id": "vital-surfing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upset-syndication"
      },
      "source": [
        ""
      ],
      "id": "upset-syndication",
      "execution_count": null,
      "outputs": []
    }
  ]
}